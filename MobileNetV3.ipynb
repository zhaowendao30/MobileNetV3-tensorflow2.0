{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.0.0\n"
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(ch, divisor=8, min_ch=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_ch is None:\n",
    "        min_ch = divisor\n",
    "    new_ch = max(min_ch, int(ch + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_ch < 0.9 * ch:\n",
    "        new_ch += divisor\n",
    "    return new_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class h_swish(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(h_swish, self).__init__()\n",
    "        self.relu = layers.ReLU(max_value=6.0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.relu(inputs) * inputs\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeBlock(layers.Layer):\n",
    "    def __init__(self, exp_size, divide = 4):\n",
    "        super(SqueezeBlock, self).__init__()\n",
    "        self.linear = Sequential([\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(exp_size // divide),\n",
    "            layers.ReLU(max_value=6.0),\n",
    "            layers.Dense(exp_size),\n",
    "        ])\n",
    "        self.h_sigmoid = tf.keras.activations.hard_sigmoid\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.linear(inputs)\n",
    "        x = self.h_sigmoid(x)\n",
    "        x = tf.reshape(x, (tf.shape(x)[0], 1, 1, tf.shape(x)[-1]))\n",
    "        out = tf.math.multiply(inputs, x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBN(layers.Layer):\n",
    "    def __init__(self, out_channel, kernel_size, stride, activation, padding):\n",
    "        super(ConvBN, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channel, kernel_size=kernel_size, strides=stride, padding=padding)\n",
    "        self.BN = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='BatchNorm')\n",
    "        self.flag = activation\n",
    "        self.relu = layers.ReLU()\n",
    "        self.h_swish = h_swish()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.BN(x)\n",
    "        if self.flag == 'relu':\n",
    "            out = self.relu(x)\n",
    "        elif self.flag == 'h_swish':\n",
    "            out = self.h_swish(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bneck(layers.Layer):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, SE, NL, exp_size, dropout_rate = 1.0):\n",
    "        super(Bneck, self).__init__()\n",
    "        self.out_channel= out_channel\n",
    "        self.SE = SE\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.NL = NL\n",
    "\n",
    "        self.shortcut = (stride == 1 and in_channel == out_channel)\n",
    "\n",
    "        if self.NL == 'RE':\n",
    "            activation = 'relu'\n",
    "        elif NL == 'HS':\n",
    "            activation = 'h_swish'\n",
    "        \n",
    "        self.ConvBN_1 = ConvBN(out_channel=exp_size, kernel_size=1, stride=1, padding='valid', activation=activation)\n",
    "\n",
    "        self.DWBN = Sequential([\n",
    "            layers.DepthwiseConv2D(kernel_size=kernel_size, strides=stride, padding='same', use_bias=False),\n",
    "            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='BatchNorm')\n",
    "        ])\n",
    "\n",
    "        if self.SE:\n",
    "            self.squeeze_block = SqueezeBlock(exp_size)\n",
    "        \n",
    "        self.ConvBN_2 = ConvBN(out_channel=out_channel, kernel_size=1, stride=1, padding='valid', activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.ConvBN_1(inputs)\n",
    "        x = self.DWBN(x)\n",
    "\n",
    "        if self.SE:\n",
    "            x = self.squeeze_block(x)\n",
    "            \n",
    "        x = self.ConvBN_2(x)\n",
    "\n",
    "        if self.shortcut:\n",
    "            return inputs + x\n",
    "        else:\n",
    "            return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MobileNetV3(mode='large', H=224, W=224, num_classes=1000, alpha = 1.0):\n",
    "    input_channel = _make_divisible(16*alpha)\n",
    "    last_channel = _make_divisible(1280*alpha)\n",
    "\n",
    "    bneck_setting = [\n",
    "        [16, 16, 3, False, 'RE', 1],\n",
    "        [64, 24, 3, False, 'RE', 2],\n",
    "        [72, 24, 3, False, 'RE', 1],\n",
    "        [72, 40, 5, True, 'RE', 2],\n",
    "        [120, 40, 5, True, 'RE', 1],\n",
    "        [120, 40, 5, True, 'RE', 1],\n",
    "        [240, 80, 3, False, 'HS', 2],\n",
    "        [200, 80, 3, False, 'HS', 1],\n",
    "        [184, 80, 3, False, 'HS', 1],\n",
    "        [184, 80, 3, False, 'HS', 1],\n",
    "        [480, 112, 3, True, 'HS', 1],\n",
    "        [672, 112, 3, True, 'HS', 1],\n",
    "        [672, 160, 5, True, 'HS', 2],\n",
    "        [960, 160, 5, True, 'HS', 1],\n",
    "        [960, 160, 5, True, 'HS', 1]\n",
    "    ]\n",
    "\n",
    "    input_image = layers.Input(shape=(H, W, 3), dtype = 'float32')\n",
    "\n",
    "    x = ConvBN(out_channel=input_channel, kernel_size=3, stride=2, padding='same', activation='h_swish')(input_image)\n",
    "\n",
    "    for exp_size, out_channel, kernel_size, SE, NL, stride in bneck_setting:\n",
    "        exp_size = _make_divisible(exp_size*alpha)\n",
    "        out_channel = _make_divisible(out_channel*alpha)\n",
    "        x = Bneck(x.shape[-1], out_channel, kernel_size, stride, SE, NL, exp_size)(x)\n",
    "    \n",
    "    last_out = _make_divisible(960*alpha)\n",
    "    x = ConvBN(last_out, kernel_size=1, stride=1, activation='h_swish', padding='valid')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(last_channel)(x)\n",
    "    x = h_swish()(x)\n",
    "    output = layers.Dense(num_classes)(x)\n",
    "\n",
    "    model = Model(inputs=input_image, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MobileNetV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_18 (InputLayer)        [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nconv_bn_103 (ConvBN)         (None, 112, 112, 16)      512       \n_________________________________________________________________\nbneck_44 (Bneck)             (None, 112, 112, 16)      880       \n_________________________________________________________________\nbneck_45 (Bneck)             (None, 56, 56, 24)        3832      \n_________________________________________________________________\nbneck_46 (Bneck)             (None, 56, 56, 24)        4872      \n_________________________________________________________________\nbneck_47 (Bneck)             (None, 28, 28, 40)        9938      \n_________________________________________________________________\nbneck_48 (Bneck)             (None, 28, 28, 40)        21230     \n_________________________________________________________________\nbneck_49 (Bneck)             (None, 28, 28, 40)        21230     \n_________________________________________________________________\nbneck_50 (Bneck)             (None, 14, 14, 80)        33520     \n_________________________________________________________________\nbneck_51 (Bneck)             (None, 14, 14, 80)        36000     \n_________________________________________________________________\nbneck_52 (Bneck)             (None, 14, 14, 80)        33152     \n_________________________________________________________________\nbneck_53 (Bneck)             (None, 14, 14, 80)        33152     \n_________________________________________________________________\nbneck_54 (Bneck)             (None, 14, 14, 112)       217160    \n_________________________________________________________________\nbneck_55 (Bneck)             (None, 14, 14, 112)       389816    \n_________________________________________________________________\nbneck_56 (Bneck)             (None, 7, 7, 160)         433064    \n_________________________________________________________________\nbneck_57 (Bneck)             (None, 7, 7, 160)         802640    \n_________________________________________________________________\nbneck_58 (Bneck)             (None, 7, 7, 160)         802640    \n_________________________________________________________________\nconv_bn_134 (ConvBN)         (None, 7, 7, 960)         158400    \n_________________________________________________________________\nglobal_average_pooling2d_24  (None, 960)               0         \n_________________________________________________________________\ndense_46 (Dense)             (None, 1280)              1230080   \n_________________________________________________________________\nh_swish_127 (h_swish)        (None, 1280)              0         \n_________________________________________________________________\ndense_47 (Dense)             (None, 1000)              1281000   \n=================================================================\nTotal params: 5,513,118\nTrainable params: 5,488,686\nNon-trainable params: 24,432\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bittf2condad21a052a10394ba5882f50851d0dfe0c",
   "display_name": "Python 3.6.10 64-bit ('tf2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}